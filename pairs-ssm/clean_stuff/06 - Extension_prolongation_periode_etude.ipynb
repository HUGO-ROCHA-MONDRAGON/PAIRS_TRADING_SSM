{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3dd5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "R√âPLICATION COMPL√àTE - Zhang (2021) | EXTENSION JUSQU'AU 31/12/2025 (NUMBA)\n",
    "===========================================================================\n",
    "\n",
    "D√©coupage demand√© (avec VRAI OOS sans leakage) :\n",
    "- Full sample: 2012-01-03 ‚Üí 2025-12-31\n",
    "- In-sample : 2012-01-10 ‚Üí 2019-12-31\n",
    "- OOS       : 2020-01-01 ‚Üí 2025-12-31\n",
    "\n",
    "‚ö†Ô∏è Correction cl√© vs version pr√©c√©dente :\n",
    "- Le seuil n_std est s√©lectionn√© SUR IS uniquement (grid search)\n",
    "- En OOS, on r√©utilise le n_std IS (pas de grid search sur OOS)\n",
    "\n",
    "Usage:\n",
    "    python Replication_Full_Appendix_2025_NUMBA.py\n",
    "    python Replication_Full_Appendix_2025_NUMBA.py ../data/dataGQ.xlsx\n",
    "\n",
    "Notebook:\n",
    "    from Replication_Full_Appendix_2025_NUMBA import main\n",
    "    tables = main(\"../data/dataGQ.xlsx\")\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "import warnings\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple, List, Dict, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# =============================================================================\n",
    "# PATHS\n",
    "# =============================================================================\n",
    "\n",
    "SCRIPT_DIR = Path(__file__).resolve().parent\n",
    "PROJECT_ROOT = SCRIPT_DIR.parent\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "DEFAULT_DATA_FILE = DATA_DIR / \"dataGQ.xlsx\"\n",
    "\n",
    "# =============================================================================\n",
    "# NUMBA (optional)\n",
    "# =============================================================================\n",
    "\n",
    "try:\n",
    "    from numba import njit\n",
    "    NUMBA_AVAILABLE = True\n",
    "    print(\"‚úÖ Numba disponible - calculs acc√©l√©r√©s\")\n",
    "except ImportError:\n",
    "    NUMBA_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è  Numba non disponible - utilisation NumPy\")\n",
    "\n",
    "    def njit(*args, **kwargs):\n",
    "        def decorator(func):\n",
    "            return func\n",
    "        if len(args) == 1 and callable(args[0]):\n",
    "            return args[0]\n",
    "        return decorator\n",
    "\n",
    "# =============================================================================\n",
    "# STOCK UNIVERSES (from Zhang 2021 Appendix)\n",
    "# =============================================================================\n",
    "\n",
    "LARGE_BANKS = ['JPM', 'BAC', 'WFC', 'C', 'USB']\n",
    "SMALL_BANKS = ['CPF', 'BANC', 'CUBI', 'NBHC', 'FCF']\n",
    "MAIN_PAIRS = [('PEP', 'KO'), ('EWT', 'EWH')]\n",
    "\n",
    "# =============================================================================\n",
    "# DATE RANGES (EXTENDED + IS/OOS SPLIT)\n",
    "# =============================================================================\n",
    "\n",
    "FULL_SAMPLE_START = '2012-01-03'\n",
    "FULL_SAMPLE_END   = '2025-12-31'\n",
    "\n",
    "IN_SAMPLE_START   = '2012-01-10'\n",
    "IN_SAMPLE_END     = '2019-12-31'\n",
    "\n",
    "OUT_SAMPLE_START  = '2020-01-01'\n",
    "OUT_SAMPLE_END    = '2025-12-31'\n",
    "\n",
    "# =============================================================================\n",
    "# DATA LOADING\n",
    "# =============================================================================\n",
    "\n",
    "@dataclass\n",
    "class PairData:\n",
    "    \"\"\"Container for pair price data.\"\"\"\n",
    "    PA: pd.Series\n",
    "    PB: pd.Series\n",
    "    asset_a: str\n",
    "    asset_b: str\n",
    "\n",
    "    @property\n",
    "    def n_obs(self) -> int:\n",
    "        return len(self.PA)\n",
    "\n",
    "\n",
    "def load_pair_data(filepath: str, col_a: str, col_b: str,\n",
    "                   start_date: str, end_date: str) -> PairData:\n",
    "    \"\"\"Load and align pair data from Excel.\n",
    "\n",
    "    Supports:\n",
    "    - Simple format: columns contain tickers and a Date column/index\n",
    "    - Bloomberg-like format: '<TICKER> US Equity' with date column adjacent\n",
    "    \"\"\"\n",
    "    df = pd.read_excel(filepath)\n",
    "\n",
    "    if col_a in df.columns:\n",
    "        if 'Date' in df.columns:\n",
    "            df = df.set_index('Date')\n",
    "        elif 'Unnamed: 0' in df.columns:\n",
    "            df = df.set_index('Unnamed: 0')\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "\n",
    "        PA = pd.to_numeric(df[col_a], errors='coerce').dropna()\n",
    "        PB = pd.to_numeric(df[col_b], errors='coerce').dropna()\n",
    "    else:\n",
    "        col_a_bb = f'{col_a} US Equity'\n",
    "        col_b_bb = f'{col_b} US Equity'\n",
    "        if col_a_bb not in df.columns:\n",
    "            col_a_bb = f'{col_a} US Equity '\n",
    "        if col_b_bb not in df.columns:\n",
    "            col_b_bb = f'{col_b} US Equity '\n",
    "\n",
    "        def get_series(_df: pd.DataFrame, col: str) -> pd.Series:\n",
    "            col_idx = _df.columns.get_loc(col)\n",
    "            date_col = _df.columns[col_idx - 1]\n",
    "            tmp = pd.DataFrame({\n",
    "                'date': pd.to_datetime(_df[date_col], errors='coerce'),\n",
    "                'price': pd.to_numeric(_df[col], errors='coerce')\n",
    "            }).dropna().drop_duplicates('date').set_index('date').sort_index()\n",
    "            return tmp['price']\n",
    "\n",
    "        PA = get_series(df, col_a_bb)\n",
    "        PB = get_series(df, col_b_bb)\n",
    "\n",
    "    common_idx = PA.index.intersection(PB.index)\n",
    "    PA, PB = PA.loc[common_idx], PB.loc[common_idx]\n",
    "\n",
    "    start, end = pd.to_datetime(start_date), pd.to_datetime(end_date)\n",
    "    mask = (PA.index >= start) & (PA.index <= end)\n",
    "\n",
    "    return PairData(PA.loc[mask], PB.loc[mask], col_a, col_b)\n",
    "\n",
    "# =============================================================================\n",
    "# MODEL PARAMETERS\n",
    "# =============================================================================\n",
    "\n",
    "@dataclass\n",
    "class ModelParams:\n",
    "    \"\"\"State-space model parameters.\"\"\"\n",
    "    theta0: float = 0.0\n",
    "    theta1: float = 0.95\n",
    "    theta2: float = 0.0\n",
    "    q_base: float = 1e-4\n",
    "    q_het: float = 0.0\n",
    "    r: float = 1e-4\n",
    "\n",
    "    @property\n",
    "    def is_homoscedastic(self) -> bool:\n",
    "        return self.q_het < 1e-10\n",
    "\n",
    "# =============================================================================\n",
    "# NUMBA-OPTIMIZED FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "@njit(cache=True)\n",
    "def halton_sequence_njit(size: int, base: int) -> np.ndarray:\n",
    "    sequence = np.zeros(size)\n",
    "    for i in range(size):\n",
    "        n = i + 1\n",
    "        f, result = 1.0, 0.0\n",
    "        while n > 0:\n",
    "            f = f / base\n",
    "            result = result + f * (n % base)\n",
    "            n = n // base\n",
    "        sequence[i] = result\n",
    "    return sequence\n",
    "\n",
    "\n",
    "@njit(cache=True)\n",
    "def kalman_filter_njit(y: np.ndarray, theta0: float, theta1: float,\n",
    "                       q: float, r: float) -> Tuple[float, np.ndarray]:\n",
    "    \"\"\"Kalman Filter for Model I.\"\"\"\n",
    "    n = len(y)\n",
    "\n",
    "    if abs(theta1) < 0.999:\n",
    "        x = theta0 / (1.0 - theta1)\n",
    "        P = q / (1.0 - theta1 * theta1)\n",
    "    else:\n",
    "        x = y[0]\n",
    "        P = q * 10.0\n",
    "\n",
    "    x_filt = np.zeros(n)\n",
    "    loglik = 0.0\n",
    "    log_2pi = np.log(2.0 * np.pi)\n",
    "\n",
    "    for t in range(n):\n",
    "        if t > 0:\n",
    "            x = theta0 + theta1 * x\n",
    "            P = theta1 * theta1 * P + q\n",
    "\n",
    "        v = y[t] - x\n",
    "        S = P + r\n",
    "\n",
    "        if S > 1e-12:\n",
    "            K = P / S\n",
    "            x = x + K * v\n",
    "            P = (1.0 - K) * P\n",
    "            loglik += -0.5 * (log_2pi + np.log(S) + v * v / S)\n",
    "\n",
    "        x_filt[t] = x\n",
    "\n",
    "    return loglik, x_filt\n",
    "\n",
    "\n",
    "@njit(cache=True)\n",
    "def qmckf_njit(y: np.ndarray, theta0: float, theta1: float,\n",
    "               q_base: float, q_het: float, r: float,\n",
    "               n_particles: int) -> Tuple[float, np.ndarray]:\n",
    "    \"\"\"QMCKF for Model II.\"\"\"\n",
    "    n = len(y)\n",
    "    x = y[0]\n",
    "    P = q_base + q_het * x * x\n",
    "\n",
    "    x_filt = np.zeros(n)\n",
    "    loglik = 0.0\n",
    "    log_2pi = np.log(2.0 * np.pi)\n",
    "\n",
    "    h1 = halton_sequence_njit(n_particles, 2)\n",
    "    h2 = halton_sequence_njit(n_particles, 3)\n",
    "\n",
    "    for i in range(n_particles):\n",
    "        h1[i] = max(1e-10, min(1.0 - 1e-10, h1[i]))\n",
    "        h2[i] = max(1e-10, min(1.0 - 1e-10, h2[i]))\n",
    "\n",
    "    z = np.zeros(n_particles)\n",
    "    for i in range(n_particles):\n",
    "        z[i] = np.sqrt(-2.0 * np.log(h1[i])) * np.cos(2.0 * np.pi * h2[i])\n",
    "\n",
    "    samples = np.zeros(n_particles)\n",
    "    f_samples = np.zeros(n_particles)\n",
    "\n",
    "    for t in range(n):\n",
    "        if t == 0:\n",
    "            x_p, P_p = x, P\n",
    "        else:\n",
    "            sqrt_P = np.sqrt(max(P, 1e-12))\n",
    "            sum_f = 0.0\n",
    "            for i in range(n_particles):\n",
    "                samples[i] = x + sqrt_P * z[i]\n",
    "                f_samples[i] = theta0 + theta1 * samples[i]\n",
    "                sum_f += f_samples[i]\n",
    "            x_p = sum_f / n_particles\n",
    "\n",
    "            sum_var, sum_g = 0.0, 0.0\n",
    "            for i in range(n_particles):\n",
    "                diff = f_samples[i] - x_p\n",
    "                sum_var += diff * diff\n",
    "                sum_g += q_base + q_het * samples[i] * samples[i]\n",
    "            P_p = sum_var / n_particles + sum_g / n_particles\n",
    "\n",
    "        v = y[t] - x_p\n",
    "        S = P_p + r\n",
    "\n",
    "        if S > 1e-12:\n",
    "            K = P_p / S\n",
    "            x = x_p + K * v\n",
    "            P = (1.0 - K) * P_p\n",
    "            loglik += -0.5 * (log_2pi + np.log(S) + v * v / S)\n",
    "        else:\n",
    "            x, P = x_p, P_p\n",
    "\n",
    "        x_filt[t] = x\n",
    "\n",
    "    return loglik, x_filt\n",
    "\n",
    "\n",
    "@njit(cache=True)\n",
    "def strategy_A_njit(x: np.ndarray, U: np.ndarray, L: np.ndarray, C: float) -> np.ndarray:\n",
    "    \"\"\"Strategy A.\"\"\"\n",
    "    n = len(x)\n",
    "    sig = np.zeros(n)\n",
    "    pos = 0\n",
    "\n",
    "    for t in range(n):\n",
    "        if pos == 0:\n",
    "            if x[t] >= U[t]:\n",
    "                pos = -1\n",
    "            elif x[t] <= L[t]:\n",
    "                pos = 1\n",
    "        elif pos == 1 and x[t] >= C:\n",
    "            pos = 0\n",
    "        elif pos == -1 and x[t] <= C:\n",
    "            pos = 0\n",
    "        sig[t] = pos\n",
    "\n",
    "    return sig\n",
    "\n",
    "\n",
    "@njit(cache=True)\n",
    "def strategy_C_njit(x: np.ndarray, U: np.ndarray, L: np.ndarray, C: float) -> np.ndarray:\n",
    "    \"\"\"Strategy C.\"\"\"\n",
    "    n = len(x)\n",
    "    sig = np.zeros(n)\n",
    "    pos = 0\n",
    "\n",
    "    for t in range(1, n):\n",
    "        prev, curr = x[t - 1], x[t]\n",
    "        U_prev, U_curr = U[t - 1], U[t]\n",
    "        L_prev, L_curr = L[t - 1], L[t]\n",
    "\n",
    "        entry_short = (prev > U_prev) and (curr <= U_curr)\n",
    "        entry_long = (prev < L_prev) and (curr >= L_curr)\n",
    "        exit_long = (prev < C) and (curr >= C)\n",
    "        exit_short = (prev > C) and (curr <= C)\n",
    "        stop_short = (prev < U_prev) and (curr >= U_curr)\n",
    "        stop_long = (prev > L_prev) and (curr <= L_curr)\n",
    "\n",
    "        if pos == 0:\n",
    "            if entry_short:\n",
    "                pos = -1\n",
    "            elif entry_long:\n",
    "                pos = 1\n",
    "        elif pos == 1 and (exit_long or stop_long):\n",
    "            pos = 0\n",
    "        elif pos == -1 and (exit_short or stop_short):\n",
    "            pos = 0\n",
    "\n",
    "        sig[t] = pos\n",
    "\n",
    "    return sig\n",
    "\n",
    "\n",
    "@njit(cache=True)\n",
    "def compute_thresholds_njit(x_filt: np.ndarray, q_base: float, q_het: float,\n",
    "                            n_std: float, is_hetero: bool) -> Tuple[np.ndarray, np.ndarray, float]:\n",
    "    \"\"\"Compute thresholds.\"\"\"\n",
    "    n = len(x_filt)\n",
    "    C = np.mean(x_filt)\n",
    "    sigma_emp = np.std(x_filt)\n",
    "\n",
    "    U = np.zeros(n)\n",
    "    L = np.zeros(n)\n",
    "\n",
    "    if is_hetero and q_het > 1e-10:\n",
    "        g_x = np.sqrt(q_base + q_het * x_filt * x_filt)\n",
    "        mean_g = np.mean(g_x)\n",
    "        for t in range(n):\n",
    "            sigma_t = g_x[t] / mean_g * sigma_emp\n",
    "            U[t] = C + n_std * sigma_t\n",
    "            L[t] = C - n_std * sigma_t\n",
    "    else:\n",
    "        threshold = n_std * sigma_emp\n",
    "        for t in range(n):\n",
    "            U[t] = C + threshold\n",
    "            L[t] = C - threshold\n",
    "\n",
    "    return U, L, C\n",
    "\n",
    "\n",
    "@njit(cache=True)\n",
    "def backtest_njit(signals: np.ndarray, x_filt: np.ndarray, cost_bp: float) -> Tuple[float, float, int]:\n",
    "    \"\"\"Backtest. Returns (annualized_return, sharpe, n_trades).\"\"\"\n",
    "    n = len(signals)\n",
    "    pnl = np.zeros(n)\n",
    "\n",
    "    n_trades = 0\n",
    "    cost_factor = 2.0 * cost_bp / 10000.0  # convention inchang√©e\n",
    "\n",
    "    for t in range(1, n):\n",
    "        dx = x_filt[t] - x_filt[t - 1]\n",
    "        pos_change = abs(signals[t] - signals[t - 1])\n",
    "        if pos_change > 0:\n",
    "            n_trades += 1\n",
    "        pnl[t] = signals[t] * dx - pos_change * cost_factor\n",
    "\n",
    "    cum_pnl = np.sum(pnl)\n",
    "\n",
    "    ann_ret = cum_pnl / (n / 252.0)\n",
    "\n",
    "    mean_pnl = np.mean(pnl)\n",
    "    std_pnl = np.std(pnl)\n",
    "    ann_std = std_pnl * np.sqrt(252.0)\n",
    "\n",
    "    if ann_std > 1e-10:\n",
    "        sharpe = (ann_ret - 0.02) / ann_std\n",
    "    else:\n",
    "        sharpe = 0.0\n",
    "\n",
    "    return ann_ret, sharpe, n_trades\n",
    "\n",
    "# =============================================================================\n",
    "# NEW: TRUE OOS (no grid search on OOS)\n",
    "# =============================================================================\n",
    "\n",
    "@njit(cache=True)\n",
    "def evaluate_fixed_nstd_njit(\n",
    "    x_filt: np.ndarray,\n",
    "    q_base: float,\n",
    "    q_het: float,\n",
    "    is_hetero: bool,\n",
    "    use_strategy_C: bool,\n",
    "    cost_bp: float,\n",
    "    n_std: float\n",
    ") -> Tuple[float, float, int]:\n",
    "    \"\"\"\n",
    "    √âvalue une strat√©gie avec un n_std FIXE (pas d'optimisation).\n",
    "    Retourne: (annualized_return, sharpe, n_trades)\n",
    "    \"\"\"\n",
    "    U, L, C = compute_thresholds_njit(x_filt, q_base, q_het, n_std, is_hetero)\n",
    "\n",
    "    if use_strategy_C:\n",
    "        sig = strategy_C_njit(x_filt, U, L, C)\n",
    "    else:\n",
    "        sig = strategy_A_njit(x_filt, U, L, C)\n",
    "\n",
    "    ann_ret, sharpe, n_trades = backtest_njit(sig, x_filt, cost_bp)\n",
    "    return ann_ret, sharpe, n_trades\n",
    "\n",
    "\n",
    "@njit(cache=True)\n",
    "def grid_search_select_nstd_njit(\n",
    "    x_filt: np.ndarray,\n",
    "    q_base: float,\n",
    "    q_het: float,\n",
    "    is_hetero: bool,\n",
    "    use_strategy_C: bool,\n",
    "    cost_bp: float\n",
    ") -> Tuple[float, float, float, int]:\n",
    "    \"\"\"\n",
    "    S√©lectionne le best_n_std SUR IS uniquement (max Sharpe), puis renvoie:\n",
    "    (best_n_std, best_return, best_sharpe, best_trades)\n",
    "    \"\"\"\n",
    "    best_n = 1.0\n",
    "    best_ret = -1e10\n",
    "    best_sr = -1e10\n",
    "    best_trades = 0\n",
    "\n",
    "    for i in range(25):\n",
    "        n_std = 0.1 + i * 0.1\n",
    "\n",
    "        ann_ret, sharpe, n_trades = evaluate_fixed_nstd_njit(\n",
    "            x_filt=x_filt,\n",
    "            q_base=q_base,\n",
    "            q_het=q_het,\n",
    "            is_hetero=is_hetero,\n",
    "            use_strategy_C=use_strategy_C,\n",
    "            cost_bp=cost_bp,\n",
    "            n_std=n_std\n",
    "        )\n",
    "\n",
    "        if n_trades > 0 and sharpe > best_sr:\n",
    "            best_sr = sharpe\n",
    "            best_ret = ann_ret\n",
    "            best_n = n_std\n",
    "            best_trades = n_trades\n",
    "\n",
    "    return best_n, best_ret, best_sr, best_trades\n",
    "\n",
    "# =============================================================================\n",
    "# ESTIMATION\n",
    "# =============================================================================\n",
    "\n",
    "def estimate_gamma_ols(log_PA: np.ndarray, log_PB: np.ndarray) -> float:\n",
    "    \"\"\"Estimate Œ≥ via OLS.\"\"\"\n",
    "    X = np.column_stack([np.ones(len(log_PB)), log_PB])\n",
    "    return float(np.linalg.lstsq(X, log_PA, rcond=None)[0][1])\n",
    "\n",
    "\n",
    "def estimate_model_I(y: np.ndarray) -> Tuple[ModelParams, np.ndarray, float]:\n",
    "    \"\"\"Estimate Model I.\"\"\"\n",
    "    y_mean, y_var = np.mean(y), np.var(y)\n",
    "    rho = np.corrcoef(y[:-1] - y_mean, y[1:] - y_mean)[0, 1]\n",
    "    theta1_init = float(np.clip(rho, 0.8, 0.99))\n",
    "\n",
    "    z0 = np.array([\n",
    "        y_mean * (1 - theta1_init),\n",
    "        np.arctanh(theta1_init),\n",
    "        np.log(y_var * (1 - theta1_init ** 2) * 0.7 + 1e-10),\n",
    "        np.log(y_var * 0.3 + 1e-10),\n",
    "    ])\n",
    "\n",
    "    def neg_ll(z):\n",
    "        try:\n",
    "            ll, _ = kalman_filter_njit(y, z[0], np.tanh(z[1]), np.exp(z[2]), np.exp(z[3]))\n",
    "            return -ll if np.isfinite(ll) else 1e10\n",
    "        except Exception:\n",
    "            return 1e10\n",
    "\n",
    "    bounds = [(-0.5, 0.5),\n",
    "              (np.arctanh(0.5), np.arctanh(0.999)),\n",
    "              (np.log(1e-8), np.log(1.0)),\n",
    "              (np.log(1e-8), np.log(1.0))]\n",
    "    res = minimize(neg_ll, z0, method='L-BFGS-B', bounds=bounds)\n",
    "\n",
    "    params = ModelParams(theta0=float(res.x[0]),\n",
    "                         theta1=float(np.tanh(res.x[1])),\n",
    "                         q_base=float(np.exp(res.x[2])),\n",
    "                         r=float(np.exp(res.x[3])))\n",
    "    ll, x_filt = kalman_filter_njit(y, params.theta0, params.theta1, params.q_base, params.r)\n",
    "\n",
    "    return params, x_filt, float(ll)\n",
    "\n",
    "\n",
    "def estimate_model_II(y: np.ndarray) -> Tuple[ModelParams, np.ndarray, float]:\n",
    "    \"\"\"Estimate Model II.\"\"\"\n",
    "    y_mean = float(np.mean(y))\n",
    "    best_ll, best_params, best_filt = -np.inf, None, None\n",
    "\n",
    "    for t0, t1, q_b, q_h, r in [\n",
    "        (y_mean * 0.01, 0.95, 0.0005, 0.10, 0.010),\n",
    "        (y_mean * 0.01, 0.93, 0.0003, 0.13, 0.011),\n",
    "        (y_mean * 0.01, 0.96, 0.0010, 0.08, 0.008),\n",
    "    ]:\n",
    "        z0 = np.array([t0, np.arctanh(t1), np.log(q_b), np.log(q_h), np.log(r)])\n",
    "\n",
    "        def neg_ll(z):\n",
    "            try:\n",
    "                ll, _ = qmckf_njit(y, z[0], np.tanh(z[1]), np.exp(z[2]), np.exp(z[3]), np.exp(z[4]), 50)\n",
    "                return -ll if np.isfinite(ll) else 1e10\n",
    "            except Exception:\n",
    "                return 1e10\n",
    "\n",
    "        bounds = [(-0.1, 0.1),\n",
    "                  (np.arctanh(0.85), np.arctanh(0.99)),\n",
    "                  (np.log(1e-6), np.log(0.005)),\n",
    "                  (np.log(0.05), np.log(0.3)),\n",
    "                  (np.log(0.005), np.log(0.05))]\n",
    "\n",
    "        try:\n",
    "            res = minimize(neg_ll, z0, method='L-BFGS-B', bounds=bounds, options={'maxiter': 500})\n",
    "            params = ModelParams(theta0=float(res.x[0]),\n",
    "                                 theta1=float(np.tanh(res.x[1])),\n",
    "                                 q_base=float(np.exp(res.x[2])),\n",
    "                                 q_het=float(np.exp(res.x[3])),\n",
    "                                 r=float(np.exp(res.x[4])))\n",
    "            ll, x_filt = qmckf_njit(y, params.theta0, params.theta1,\n",
    "                                    params.q_base, params.q_het, params.r, 100)\n",
    "            if ll > best_ll:\n",
    "                best_ll, best_params, best_filt = float(ll), params, x_filt\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    if best_params is None:\n",
    "        best_params = ModelParams(theta0=0.0, theta1=0.95, q_base=0.0003, q_het=0.1, r=0.01)\n",
    "        ll, x_filt = qmckf_njit(y, 0.0, 0.95, 0.0003, 0.1, 0.01, 100)\n",
    "        best_ll, best_filt = float(ll), x_filt\n",
    "\n",
    "    return best_params, best_filt, float(best_ll)\n",
    "\n",
    "# =============================================================================\n",
    "# PAIR ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "def analyze_pair(pair: PairData, cost_bp: float = 20.0) -> Dict:\n",
    "    \"\"\"Analyze a single pair (FULL sample style).\"\"\"\n",
    "    log_PA, log_PB = np.log(pair.PA.values), np.log(pair.PB.values)\n",
    "    gamma = estimate_gamma_ols(log_PA, log_PB)\n",
    "    y = log_PA - gamma * log_PB\n",
    "\n",
    "    # Model I + Strategy A (select n_std on full)\n",
    "    p1, f1, _ = estimate_model_I(y)\n",
    "    n1, ret_m1, sr_m1, tr_m1 = grid_search_select_nstd_njit(f1, p1.q_base, 0.0, False, False, cost_bp)\n",
    "\n",
    "    # Model II + Strategy C (select n_std on full)\n",
    "    p2, f2, _ = estimate_model_II(y)\n",
    "    n2, ret_m2, sr_m2, tr_m2 = grid_search_select_nstd_njit(f2, p2.q_base, p2.q_het, True, True, cost_bp)\n",
    "\n",
    "    return {\n",
    "        'Stock1': pair.asset_a,\n",
    "        'Stock2': pair.asset_b,\n",
    "\n",
    "        'M1_nstd': float(n1),\n",
    "        'M1_Return': float(ret_m1),\n",
    "        'M1_Sharpe': float(sr_m1),\n",
    "        'M1_Trades': int(tr_m1),\n",
    "\n",
    "        'M2_nstd': float(n2),\n",
    "        'M2_Return': float(ret_m2),\n",
    "        'M2_Sharpe': float(sr_m2),\n",
    "        'M2_Trades': int(tr_m2),\n",
    "\n",
    "        'Imp_Return': float((ret_m2 / ret_m1 - 1) * 100) if abs(ret_m1) > 1e-6 else 0.0,\n",
    "        'Imp_Sharpe': float((sr_m2 / sr_m1 - 1) * 100) if abs(sr_m1) > 1e-6 else 0.0,\n",
    "    }\n",
    "\n",
    "\n",
    "def analyze_pair_insample_oos(filepath: str, col_a: str, col_b: str,\n",
    "                             is_start: str, is_end: str,\n",
    "                             oos_start: str, oos_end: str,\n",
    "                             cost_bp: float = 20.0) -> Tuple[Optional[Dict], Optional[Dict]]:\n",
    "    \"\"\"\n",
    "    IS:\n",
    "      - estimate params on IS\n",
    "      - select best_n_std on IS (grid search)\n",
    "    OOS:\n",
    "      - apply IS gamma + IS params to filter OOS\n",
    "      - evaluate with IS best_n_std (NO grid search)\n",
    "    \"\"\"\n",
    "\n",
    "    # -----------------------\n",
    "    # In-Sample\n",
    "    # -----------------------\n",
    "    try:\n",
    "        pair_is = load_pair_data(filepath, col_a, col_b, is_start, is_end)\n",
    "        log_PA_is, log_PB_is = np.log(pair_is.PA.values), np.log(pair_is.PB.values)\n",
    "        gamma_is = estimate_gamma_ols(log_PA_is, log_PB_is)\n",
    "        y_is = log_PA_is - gamma_is * log_PB_is\n",
    "\n",
    "        # Model I (IS)\n",
    "        p1_is, f1_is, _ = estimate_model_I(y_is)\n",
    "        n1_is, ret_m1_is, sr_m1_is, tr_m1_is = grid_search_select_nstd_njit(\n",
    "            f1_is, p1_is.q_base, 0.0, False, False, cost_bp\n",
    "        )\n",
    "\n",
    "        # Model II (IS)\n",
    "        p2_is, f2_is, _ = estimate_model_II(y_is)\n",
    "        n2_is, ret_m2_is, sr_m2_is, tr_m2_is = grid_search_select_nstd_njit(\n",
    "            f2_is, p2_is.q_base, p2_is.q_het, True, True, cost_bp\n",
    "        )\n",
    "\n",
    "        result_is = {\n",
    "            'Stock1': col_a, 'Stock2': col_b,\n",
    "\n",
    "            'M1_nstd': float(n1_is),\n",
    "            'M1_Return': float(ret_m1_is),\n",
    "            'M1_Sharpe': float(sr_m1_is),\n",
    "            'M1_Trades': int(tr_m1_is),\n",
    "\n",
    "            'M2_nstd': float(n2_is),\n",
    "            'M2_Return': float(ret_m2_is),\n",
    "            'M2_Sharpe': float(sr_m2_is),\n",
    "            'M2_Trades': int(tr_m2_is),\n",
    "\n",
    "            'Imp_Return': float((ret_m2_is / ret_m1_is - 1) * 100) if abs(ret_m1_is) > 1e-6 else 0.0,\n",
    "            'Imp_Sharpe': float((sr_m2_is / sr_m1_is - 1) * 100) if abs(sr_m1_is) > 1e-6 else 0.0,\n",
    "        }\n",
    "    except Exception:\n",
    "        return None, None\n",
    "\n",
    "    # -----------------------\n",
    "    # Out-of-Sample (TRUE OOS)\n",
    "    # -----------------------\n",
    "    try:\n",
    "        pair_oos = load_pair_data(filepath, col_a, col_b, oos_start, oos_end)\n",
    "        log_PA_oos, log_PB_oos = np.log(pair_oos.PA.values), np.log(pair_oos.PB.values)\n",
    "        y_oos = log_PA_oos - gamma_is * log_PB_oos  # keep IS gamma\n",
    "\n",
    "        # Filter OOS with IS params\n",
    "        _, f1_oos = kalman_filter_njit(y_oos, p1_is.theta0, p1_is.theta1, p1_is.q_base, p1_is.r)\n",
    "        _, f2_oos = qmckf_njit(y_oos, p2_is.theta0, p2_is.theta1, p2_is.q_base, p2_is.q_het, p2_is.r, 100)\n",
    "\n",
    "        # Evaluate with IS-selected n_std (NO grid search)\n",
    "        ret_m1_oos, sr_m1_oos, tr_m1_oos = evaluate_fixed_nstd_njit(\n",
    "            f1_oos, p1_is.q_base, 0.0, False, False, cost_bp, float(n1_is)\n",
    "        )\n",
    "        ret_m2_oos, sr_m2_oos, tr_m2_oos = evaluate_fixed_nstd_njit(\n",
    "            f2_oos, p2_is.q_base, p2_is.q_het, True, True, cost_bp, float(n2_is)\n",
    "        )\n",
    "\n",
    "        result_oos = {\n",
    "            'Stock1': col_a, 'Stock2': col_b,\n",
    "\n",
    "            'M1_nstd': float(n1_is),\n",
    "            'M1_Return': float(ret_m1_oos),\n",
    "            'M1_Sharpe': float(sr_m1_oos),\n",
    "            'M1_Trades': int(tr_m1_oos),\n",
    "\n",
    "            'M2_nstd': float(n2_is),\n",
    "            'M2_Return': float(ret_m2_oos),\n",
    "            'M2_Sharpe': float(sr_m2_oos),\n",
    "            'M2_Trades': int(tr_m2_oos),\n",
    "\n",
    "            'Imp_Return': float((ret_m2_oos / ret_m1_oos - 1) * 100) if abs(ret_m1_oos) > 1e-6 else 0.0,\n",
    "            'Imp_Sharpe': float((sr_m2_oos / sr_m1_oos - 1) * 100) if abs(sr_m1_oos) > 1e-6 else 0.0,\n",
    "        }\n",
    "    except Exception:\n",
    "        result_oos = None\n",
    "\n",
    "    return result_is, result_oos\n",
    "\n",
    "# =============================================================================\n",
    "# TABLE GENERATION\n",
    "# =============================================================================\n",
    "\n",
    "def generate_pairs_within_group(stocks: List[str]) -> List[Tuple[str, str]]:\n",
    "    return list(itertools.combinations(stocks, 2))\n",
    "\n",
    "\n",
    "def generate_pairs_between_groups(group1: List[str], group2: List[str]) -> List[Tuple[str, str]]:\n",
    "    return list(itertools.product(group1, group2))\n",
    "\n",
    "\n",
    "def replicate_table(filepath: str, pairs: List[Tuple[str, str]],\n",
    "                    start_date: str, end_date: str, table_name: str,\n",
    "                    cost_bp: float = 20.0) -> pd.DataFrame:\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(f\"  {table_name}\")\n",
    "    print(f\"  Period: {start_date} to {end_date}\")\n",
    "    print(f\"  Pairs: {len(pairs)}\")\n",
    "    print(f\"{'=' * 80}\")\n",
    "\n",
    "    results = []\n",
    "    for i, (col_a, col_b) in enumerate(pairs):\n",
    "        try:\n",
    "            pair = load_pair_data(filepath, col_a, col_b, start_date, end_date)\n",
    "            result = analyze_pair(pair, cost_bp=cost_bp)\n",
    "            results.append(result)\n",
    "            print(f\"  {i + 1:2d}. {col_a}-{col_b}: M1 SR={result['M1_Sharpe']:.4f}, M2 SR={result['M2_Sharpe']:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  {i + 1:2d}. {col_a}-{col_b}: ‚ùå Error - {e}\")\n",
    "\n",
    "    return pd.DataFrame(results) if results else pd.DataFrame()\n",
    "\n",
    "\n",
    "def replicate_table_is_oos(filepath: str, pairs: List[Tuple[str, str]],\n",
    "                           is_start: str, is_end: str,\n",
    "                           oos_start: str, oos_end: str,\n",
    "                           table_name: str,\n",
    "                           cost_bp: float = 20.0) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(f\"  {table_name}\")\n",
    "    print(f\"  In-Sample: {is_start} to {is_end}\")\n",
    "    print(f\"  Out-of-Sample: {oos_start} to {oos_end}\")\n",
    "    print(f\"  Pairs: {len(pairs)}\")\n",
    "    print(f\"{'=' * 80}\")\n",
    "\n",
    "    results_is, results_oos = [], []\n",
    "\n",
    "    for i, (col_a, col_b) in enumerate(pairs):\n",
    "        try:\n",
    "            res_is, res_oos = analyze_pair_insample_oos(\n",
    "                filepath, col_a, col_b,\n",
    "                is_start, is_end,\n",
    "                oos_start, oos_end,\n",
    "                cost_bp=cost_bp\n",
    "            )\n",
    "            if res_is is not None:\n",
    "                results_is.append(res_is)\n",
    "            if res_oos is not None:\n",
    "                results_oos.append(res_oos)\n",
    "\n",
    "            if res_is is not None and res_oos is not None:\n",
    "                print(f\"  {i + 1:2d}. {col_a}-{col_b}: IS M2 SR={res_is['M2_Sharpe']:.4f}, OOS M2 SR={res_oos['M2_Sharpe']:.4f}\")\n",
    "            else:\n",
    "                print(f\"  {i + 1:2d}. {col_a}-{col_b}: ‚ö†Ô∏è Missing IS/OOS result\")\n",
    "        except Exception as e:\n",
    "            print(f\"  {i + 1:2d}. {col_a}-{col_b}: ‚ùå Error - {e}\")\n",
    "\n",
    "    df_is = pd.DataFrame(results_is) if results_is else pd.DataFrame()\n",
    "    df_oos = pd.DataFrame(results_oos) if results_oos else pd.DataFrame()\n",
    "\n",
    "    return df_is, df_oos\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN\n",
    "# =============================================================================\n",
    "\n",
    "def main(data_path: str | None = None, cost_bp: float = 20.0) -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"Main function to replicate all tables. Returns dict of DataFrames (for notebook use).\"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    if data_path is None:\n",
    "        data_path = str(DEFAULT_DATA_FILE)\n",
    "    else:\n",
    "        data_path = str(Path(data_path))\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(\"ZHANG (2021) - FULL REPLICATION (NUMBA) | EXTENDED TO 2025\")\n",
    "    print(f\"FULL: {FULL_SAMPLE_START} ‚Üí {FULL_SAMPLE_END}\")\n",
    "    print(f\"IS  : {IN_SAMPLE_START} ‚Üí {IN_SAMPLE_END}\")\n",
    "    print(f\"OOS : {OUT_SAMPLE_START} ‚Üí {OUT_SAMPLE_END}\")\n",
    "    print(\"OOS: TRUE (n_std selected on IS, reused in OOS)\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\nData: {data_path}\")\n",
    "    print(f\"Numba: {'‚úÖ Enabled' if NUMBA_AVAILABLE else '‚ùå Disabled'}\")\n",
    "    print(f\"Cost (bp): {cost_bp}\")\n",
    "\n",
    "    # Warm-up JIT\n",
    "    if NUMBA_AVAILABLE:\n",
    "        print(\"\\n‚è≥ JIT Compilation warm-up...\")\n",
    "        dummy = np.random.randn(200).astype(np.float64)\n",
    "        _ = kalman_filter_njit(dummy, 0.0, 0.95, 0.001, 0.001)\n",
    "        _ = qmckf_njit(dummy, 0.0, 0.95, 0.001, 0.1, 0.01, 50)\n",
    "        _ = evaluate_fixed_nstd_njit(dummy, 0.001, 0.1, True, True, 20.0, 1.5)\n",
    "        _ = grid_search_select_nstd_njit(dummy, 0.001, 0.1, True, True, 20.0)\n",
    "        print(\"‚úÖ Done!\")\n",
    "\n",
    "    all_tables: Dict[str, pd.DataFrame] = {}\n",
    "\n",
    "    # TABLE 2 & 3: Main Pairs (full extended)\n",
    "    print(\"\\n\" + \"#\" * 80)\n",
    "    print(\"# TABLES 2 & 3: MAIN PAIRS (FULL 2012‚Äì2025)\")\n",
    "    print(\"#\" * 80)\n",
    "\n",
    "    main_results = []\n",
    "    for col_a, col_b in MAIN_PAIRS:\n",
    "        try:\n",
    "            pair = load_pair_data(data_path, col_a, col_b, FULL_SAMPLE_START, FULL_SAMPLE_END)\n",
    "            print(f\"\\nüìä {col_a}-{col_b}: {pair.n_obs} observations (FULL)\")\n",
    "            result = analyze_pair(pair, cost_bp=cost_bp)\n",
    "            main_results.append(result)\n",
    "            print(f\"   Model I + Strategy A: Return={result['M1_Return']:.4f}, Sharpe={result['M1_Sharpe']:.4f}, n_std={result['M1_nstd']:.2f}\")\n",
    "            print(f\"   Model II + Strategy C: Return={result['M2_Return']:.4f}, Sharpe={result['M2_Sharpe']:.4f}, n_std={result['M2_nstd']:.2f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå {col_a}-{col_b}: Error - {e}\")\n",
    "\n",
    "    all_tables['Table_2_3_FULL'] = pd.DataFrame(main_results)\n",
    "\n",
    "    # A1: within-group banks (full extended)\n",
    "    print(\"\\n\" + \"#\" * 80)\n",
    "    print(\"# TABLE A1: WITHIN-GROUP BANK PAIRS (FULL 2012‚Äì2025)\")\n",
    "    print(\"#\" * 80)\n",
    "\n",
    "    large_pairs = generate_pairs_within_group(LARGE_BANKS)\n",
    "    small_pairs = generate_pairs_within_group(SMALL_BANKS)\n",
    "\n",
    "    df_a1_large = replicate_table(data_path, large_pairs, FULL_SAMPLE_START, FULL_SAMPLE_END,\n",
    "                                  \"Table A1 - Panel A: Large Banks (FULL)\", cost_bp=cost_bp)\n",
    "    df_a1_small = replicate_table(data_path, small_pairs, FULL_SAMPLE_START, FULL_SAMPLE_END,\n",
    "                                  \"Table A1 - Panel B: Small Banks (FULL)\", cost_bp=cost_bp)\n",
    "\n",
    "    all_tables['Table_A1_Large_FULL'] = df_a1_large\n",
    "    all_tables['Table_A1_Small_FULL'] = df_a1_small\n",
    "\n",
    "    # A2: cross banks (full extended)\n",
    "    print(\"\\n\" + \"#\" * 80)\n",
    "    print(\"# TABLE A2: LARGE √ó SMALL BANKS (FULL 2012‚Äì2025)\")\n",
    "    print(\"#\" * 80)\n",
    "\n",
    "    cross_pairs = generate_pairs_between_groups(LARGE_BANKS, SMALL_BANKS)\n",
    "    df_a2 = replicate_table(data_path, cross_pairs, FULL_SAMPLE_START, FULL_SAMPLE_END,\n",
    "                            \"Table A2: Large √ó Small Banks (FULL)\", cost_bp=cost_bp)\n",
    "    all_tables['Table_A2_Cross_FULL'] = df_a2\n",
    "\n",
    "    # A3/A4/A5/A6: IS/OOS with new split (TRUE OOS)\n",
    "    print(\"\\n\" + \"#\" * 80)\n",
    "    print(\"# TABLES A3-A6: IS/OOS SPLIT (IS: 2012‚Äì2019 | OOS: 2020‚Äì2025)\")\n",
    "    print(\"#\" * 80)\n",
    "\n",
    "    df_a3_is, df_a3_oos = replicate_table_is_oos(\n",
    "        data_path, large_pairs,\n",
    "        IN_SAMPLE_START, IN_SAMPLE_END,\n",
    "        OUT_SAMPLE_START, OUT_SAMPLE_END,\n",
    "        \"Table A3: Large Banks IS/OOS\", cost_bp=cost_bp\n",
    "    )\n",
    "    all_tables['Table_A3_IS'] = df_a3_is\n",
    "    all_tables['Table_A3_OOS'] = df_a3_oos\n",
    "\n",
    "    df_a4_is, df_a4_oos = replicate_table_is_oos(\n",
    "        data_path, small_pairs,\n",
    "        IN_SAMPLE_START, IN_SAMPLE_END,\n",
    "        OUT_SAMPLE_START, OUT_SAMPLE_END,\n",
    "        \"Table A4: Small Banks IS/OOS\", cost_bp=cost_bp\n",
    "    )\n",
    "    all_tables['Table_A4_IS'] = df_a4_is\n",
    "    all_tables['Table_A4_OOS'] = df_a4_oos\n",
    "\n",
    "    df_a5_is, df_a6_oos = replicate_table_is_oos(\n",
    "        data_path, cross_pairs,\n",
    "        IN_SAMPLE_START, IN_SAMPLE_END,\n",
    "        OUT_SAMPLE_START, OUT_SAMPLE_END,\n",
    "        \"Tables A5/A6: Large √ó Small IS/OOS\", cost_bp=cost_bp\n",
    "    )\n",
    "    all_tables['Table_A5_IS'] = df_a5_is\n",
    "    all_tables['Table_A6_OOS'] = df_a6_oos\n",
    "\n",
    "    # FINAL SUMMARY\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"FINAL SUMMARY\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    for name, df in all_tables.items():\n",
    "        if df is not None and not df.empty and ('M1_Sharpe' in df.columns) and ('M2_Sharpe' in df.columns):\n",
    "            print(f\"\\n{name}:\")\n",
    "            print(f\"  Pairs: {len(df)}\")\n",
    "            print(f\"  Mean M1 Sharpe: {df['M1_Sharpe'].mean():.4f}\")\n",
    "            print(f\"  Mean M2 Sharpe: {df['M2_Sharpe'].mean():.4f}\")\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\n‚è±Ô∏è  Total time: {elapsed:.1f} seconds\")\n",
    "\n",
    "    return all_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d234d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Numba disponible - calculs acc√©l√©r√©s\n",
      "================================================================================\n",
      "ZHANG (2021) - FULL REPLICATION (NUMBA) | EXTENDED TO 2025\n",
      "FULL: 2012-01-03 ‚Üí 2025-12-31\n",
      "IS  : 2012-01-10 ‚Üí 2019-12-31\n",
      "OOS : 2020-01-01 ‚Üí 2025-12-31\n",
      "OOS: TRUE (n_std selected on IS, reused in OOS)\n",
      "================================================================================\n",
      "\n",
      "Data: ../data/dataGQ.xlsx\n",
      "Numba: ‚úÖ Enabled\n",
      "Cost (bp): 20.0\n",
      "\n",
      "‚è≥ JIT Compilation warm-up...\n",
      "‚úÖ Done!\n",
      "\n",
      "################################################################################\n",
      "# TABLES 2 & 3: MAIN PAIRS (FULL 2012‚Äì2025)\n",
      "################################################################################\n",
      "\n",
      "üìä PEP-KO: 3520 observations (FULL)\n",
      "   Model I + Strategy A: Return=0.0333, Sharpe=0.1229, n_std=2.10\n",
      "   Model II + Strategy C: Return=0.0390, Sharpe=0.3908, n_std=0.80\n",
      "\n",
      "üìä EWT-EWH: 3520 observations (FULL)\n",
      "   Model I + Strategy A: Return=0.0236, Sharpe=0.0266, n_std=1.50\n",
      "   Model II + Strategy C: Return=0.0527, Sharpe=0.3416, n_std=0.80\n",
      "\n",
      "################################################################################\n",
      "# TABLE A1: WITHIN-GROUP BANK PAIRS (FULL 2012‚Äì2025)\n",
      "################################################################################\n",
      "\n",
      "================================================================================\n",
      "  Table A1 - Panel A: Large Banks (FULL)\n",
      "  Period: 2012-01-03 to 2025-12-31\n",
      "  Pairs: 10\n",
      "================================================================================\n",
      "   1. JPM-BAC: M1 SR=0.3744, M2 SR=0.6361\n",
      "   2. JPM-WFC: M1 SR=0.4747, M2 SR=0.1625\n",
      "   3. JPM-C: M1 SR=0.4707, M2 SR=0.9507\n",
      "   4. JPM-USB: M1 SR=0.0014, M2 SR=0.4974\n",
      "   5. BAC-WFC: M1 SR=0.9029, M2 SR=0.3581\n",
      "   6. BAC-C: M1 SR=0.2725, M2 SR=0.7012\n",
      "   7. BAC-USB: M1 SR=0.2304, M2 SR=0.7702\n",
      "   8. WFC-C: M1 SR=0.1474, M2 SR=1.0032\n",
      "   9. WFC-USB: M1 SR=0.1891, M2 SR=0.5186\n",
      "  10. C-USB: M1 SR=0.2144, M2 SR=1.2386\n",
      "\n",
      "================================================================================\n",
      "  Table A1 - Panel B: Small Banks (FULL)\n",
      "  Period: 2012-01-03 to 2025-12-31\n",
      "  Pairs: 10\n",
      "================================================================================\n",
      "   1. CPF-BANC: M1 SR=0.4536, M2 SR=1.1490\n",
      "   2. CPF-CUBI: M1 SR=0.5967, M2 SR=1.2283\n",
      "   3. CPF-NBHC: M1 SR=0.5323, M2 SR=0.9942\n",
      "   4. CPF-FCF: M1 SR=0.2752, M2 SR=0.7799\n",
      "   5. BANC-CUBI: M1 SR=0.3623, M2 SR=1.2870\n",
      "   6. BANC-NBHC: M1 SR=0.3083, M2 SR=1.1443\n",
      "   7. BANC-FCF: M1 SR=0.2782, M2 SR=1.1861\n",
      "   8. CUBI-NBHC: M1 SR=0.7109, M2 SR=0.8727\n",
      "   9. CUBI-FCF: M1 SR=0.3588, M2 SR=1.1950\n",
      "  10. NBHC-FCF: M1 SR=0.1730, M2 SR=0.9247\n",
      "\n",
      "################################################################################\n",
      "# TABLE A2: LARGE √ó SMALL BANKS (FULL 2012‚Äì2025)\n",
      "################################################################################\n",
      "\n",
      "================================================================================\n",
      "  Table A2: Large √ó Small Banks (FULL)\n",
      "  Period: 2012-01-03 to 2025-12-31\n",
      "  Pairs: 25\n",
      "================================================================================\n",
      "   1. JPM-CPF: M1 SR=0.0254, M2 SR=0.3830\n",
      "   2. JPM-BANC: M1 SR=0.1992, M2 SR=0.5173\n",
      "   3. JPM-CUBI: M1 SR=0.5087, M2 SR=1.0352\n",
      "   4. JPM-NBHC: M1 SR=0.0765, M2 SR=1.0726\n",
      "   5. JPM-FCF: M1 SR=0.3000, M2 SR=1.1426\n",
      "   6. BAC-CPF: M1 SR=0.2934, M2 SR=0.6115\n",
      "   7. BAC-BANC: M1 SR=0.7385, M2 SR=0.3915\n",
      "   8. BAC-CUBI: M1 SR=0.4464, M2 SR=0.8978\n",
      "   9. BAC-NBHC: M1 SR=0.6064, M2 SR=1.6733\n",
      "  10. BAC-FCF: M1 SR=0.5052, M2 SR=1.4690\n",
      "  11. WFC-CPF: M1 SR=0.1147, M2 SR=0.8836\n",
      "  12. WFC-BANC: M1 SR=0.2247, M2 SR=0.9089\n",
      "  13. WFC-CUBI: M1 SR=0.1268, M2 SR=0.7933\n",
      "  14. WFC-NBHC: M1 SR=0.2067, M2 SR=0.9812\n",
      "  15. WFC-FCF: M1 SR=0.2238, M2 SR=0.8357\n",
      "  16. C-CPF: M1 SR=0.3317, M2 SR=1.5459\n",
      "  17. C-BANC: M1 SR=0.3753, M2 SR=1.4000\n",
      "  18. C-CUBI: M1 SR=0.6113, M2 SR=1.4196\n",
      "  19. C-NBHC: M1 SR=0.9078, M2 SR=1.3133\n",
      "  20. C-FCF: M1 SR=0.4590, M2 SR=1.3281\n",
      "  21. USB-CPF: M1 SR=0.3284, M2 SR=1.3234\n",
      "  22. USB-BANC: M1 SR=0.5434, M2 SR=1.1541\n",
      "  23. USB-CUBI: M1 SR=0.5402, M2 SR=1.1229\n",
      "  24. USB-NBHC: M1 SR=0.3723, M2 SR=1.0113\n",
      "  25. USB-FCF: M1 SR=0.4864, M2 SR=0.8639\n",
      "\n",
      "################################################################################\n",
      "# TABLES A3-A6: IS/OOS SPLIT (IS: 2012‚Äì2019 | OOS: 2020‚Äì2025)\n",
      "################################################################################\n",
      "\n",
      "================================================================================\n",
      "  Table A3: Large Banks IS/OOS\n",
      "  In-Sample: 2012-01-10 to 2019-12-31\n",
      "  Out-of-Sample: 2020-01-01 to 2025-12-31\n",
      "  Pairs: 10\n",
      "================================================================================\n",
      "   1. JPM-BAC: IS M2 SR=0.9008, OOS M2 SR=0.5046\n",
      "   2. JPM-WFC: IS M2 SR=0.6344, OOS M2 SR=1.7594\n",
      "   3. JPM-C: IS M2 SR=0.8214, OOS M2 SR=1.2969\n",
      "   4. JPM-USB: IS M2 SR=1.0780, OOS M2 SR=0.8476\n",
      "   5. BAC-WFC: IS M2 SR=0.9542, OOS M2 SR=0.6603\n",
      "   6. BAC-C: IS M2 SR=1.5373, OOS M2 SR=1.2504\n",
      "   7. BAC-USB: IS M2 SR=1.6888, OOS M2 SR=1.6671\n",
      "   8. WFC-C: IS M2 SR=0.9675, OOS M2 SR=0.2719\n",
      "   9. WFC-USB: IS M2 SR=0.6385, OOS M2 SR=0.3227\n",
      "  10. C-USB: IS M2 SR=1.4646, OOS M2 SR=1.5734\n",
      "\n",
      "================================================================================\n",
      "  Table A4: Small Banks IS/OOS\n",
      "  In-Sample: 2012-01-10 to 2019-12-31\n",
      "  Out-of-Sample: 2020-01-01 to 2025-12-31\n",
      "  Pairs: 10\n",
      "================================================================================\n",
      "   1. CPF-BANC: IS M2 SR=1.3065, OOS M2 SR=0.9988\n",
      "   2. CPF-CUBI: IS M2 SR=1.1740, OOS M2 SR=0.7790\n",
      "   3. CPF-NBHC: IS M2 SR=1.0534, OOS M2 SR=0.4660\n",
      "   4. CPF-FCF: IS M2 SR=1.3227, OOS M2 SR=0.6192\n",
      "   5. BANC-CUBI: IS M2 SR=1.5877, OOS M2 SR=0.7211\n",
      "   6. BANC-NBHC: IS M2 SR=1.3653, OOS M2 SR=1.4044\n",
      "   7. BANC-FCF: IS M2 SR=1.3832, OOS M2 SR=1.2676\n",
      "   8. CUBI-NBHC: IS M2 SR=0.9648, OOS M2 SR=1.2114\n",
      "   9. CUBI-FCF: IS M2 SR=0.8982, OOS M2 SR=1.0020\n",
      "  10. NBHC-FCF: IS M2 SR=1.3317, OOS M2 SR=1.1276\n",
      "\n",
      "================================================================================\n",
      "  Tables A5/A6: Large √ó Small IS/OOS\n",
      "  In-Sample: 2012-01-10 to 2019-12-31\n",
      "  Out-of-Sample: 2020-01-01 to 2025-12-31\n",
      "  Pairs: 25\n",
      "================================================================================\n",
      "   1. JPM-CPF: IS M2 SR=1.1320, OOS M2 SR=0.8453\n",
      "   2. JPM-BANC: IS M2 SR=1.0881, OOS M2 SR=1.0239\n",
      "   3. JPM-CUBI: IS M2 SR=0.8751, OOS M2 SR=1.4733\n",
      "   4. JPM-NBHC: IS M2 SR=1.8265, OOS M2 SR=1.1008\n",
      "   5. JPM-FCF: IS M2 SR=1.5199, OOS M2 SR=1.3357\n",
      "   6. BAC-CPF: IS M2 SR=1.4912, OOS M2 SR=1.1672\n",
      "   7. BAC-BANC: IS M2 SR=0.9817, OOS M2 SR=0.8009\n",
      "   8. BAC-CUBI: IS M2 SR=0.9814, OOS M2 SR=1.3726\n",
      "   9. BAC-NBHC: IS M2 SR=1.7064, OOS M2 SR=1.1403\n",
      "  10. BAC-FCF: IS M2 SR=1.4289, OOS M2 SR=-1.0221\n",
      "  11. WFC-CPF: IS M2 SR=1.0024, OOS M2 SR=0.5865\n",
      "  12. WFC-BANC: IS M2 SR=1.1569, OOS M2 SR=0.7049\n",
      "  13. WFC-CUBI: IS M2 SR=1.3248, OOS M2 SR=1.3964\n",
      "  14. WFC-NBHC: IS M2 SR=1.2307, OOS M2 SR=0.6541\n",
      "  15. WFC-FCF: IS M2 SR=0.9229, OOS M2 SR=0.9845\n",
      "  16. C-CPF: IS M2 SR=1.6611, OOS M2 SR=1.5021\n",
      "  17. C-BANC: IS M2 SR=0.7945, OOS M2 SR=0.7173\n",
      "  18. C-CUBI: IS M2 SR=1.0873, OOS M2 SR=1.1626\n",
      "  19. C-NBHC: IS M2 SR=1.5507, OOS M2 SR=0.9797\n",
      "  20. C-FCF: IS M2 SR=1.0866, OOS M2 SR=1.0843\n",
      "  21. USB-CPF: IS M2 SR=1.2860, OOS M2 SR=1.7178\n",
      "  22. USB-BANC: IS M2 SR=0.7861, OOS M2 SR=1.5529\n",
      "  23. USB-CUBI: IS M2 SR=0.9864, OOS M2 SR=0.5214\n",
      "  24. USB-NBHC: IS M2 SR=0.9202, OOS M2 SR=1.0919\n",
      "  25. USB-FCF: IS M2 SR=0.9010, OOS M2 SR=0.8753\n",
      "\n",
      "================================================================================\n",
      "FINAL SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Table_2_3_FULL:\n",
      "  Pairs: 2\n",
      "  Mean M1 Sharpe: 0.0747\n",
      "  Mean M2 Sharpe: 0.3662\n",
      "\n",
      "Table_A1_Large_FULL:\n",
      "  Pairs: 10\n",
      "  Mean M1 Sharpe: 0.3278\n",
      "  Mean M2 Sharpe: 0.6837\n",
      "\n",
      "Table_A1_Small_FULL:\n",
      "  Pairs: 10\n",
      "  Mean M1 Sharpe: 0.4049\n",
      "  Mean M2 Sharpe: 1.0761\n",
      "\n",
      "Table_A2_Cross_FULL:\n",
      "  Pairs: 25\n",
      "  Mean M1 Sharpe: 0.3821\n",
      "  Mean M2 Sharpe: 1.0431\n",
      "\n",
      "Table_A3_IS:\n",
      "  Pairs: 10\n",
      "  Mean M1 Sharpe: 0.4876\n",
      "  Mean M2 Sharpe: 1.0685\n",
      "\n",
      "Table_A3_OOS:\n",
      "  Pairs: 10\n",
      "  Mean M1 Sharpe: 0.1839\n",
      "  Mean M2 Sharpe: 1.0154\n",
      "\n",
      "Table_A4_IS:\n",
      "  Pairs: 10\n",
      "  Mean M1 Sharpe: 0.4876\n",
      "  Mean M2 Sharpe: 1.2387\n",
      "\n",
      "Table_A4_OOS:\n",
      "  Pairs: 10\n",
      "  Mean M1 Sharpe: 0.3977\n",
      "  Mean M2 Sharpe: 0.9597\n",
      "\n",
      "Table_A5_IS:\n",
      "  Pairs: 25\n",
      "  Mean M1 Sharpe: 0.5549\n",
      "  Mean M2 Sharpe: 1.1892\n",
      "\n",
      "Table_A6_OOS:\n",
      "  Pairs: 25\n",
      "  Mean M1 Sharpe: 0.2429\n",
      "  Mean M2 Sharpe: 0.9908\n",
      "\n",
      "‚è±Ô∏è  Total time: 487.8 seconds\n"
     ]
    }
   ],
   "source": [
    "tables = main(\"../data/dataGQ.xlsx\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
